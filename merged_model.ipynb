{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54473,"status":"ok","timestamp":1709971057241,"user":{"displayName":"Roham Jahangiri","userId":"05128575011789052582"},"user_tz":-210},"id":"fzlrpgcVBvZW","outputId":"4fbb9a06-2fb0-4c5b-f15b-9c15d053fd47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIwkl6vdMka-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709971064979,"user_tz":-210,"elapsed":454,"user":{"displayName":"Roham Jahangiri","userId":"05128575011789052582"}},"outputId":"7318e0ae-f1d7-4923-cb3e-eaa80e3a143f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}],"source":["%cd '/content/drive/MyDrive'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5KmBxL842CDf"},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold (n_splits = 5, shuffle = True, random_state = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WqdgK3AfLh-"},"outputs":[],"source":["import tensorflow as tf\n","from keras.layers import Input\n","import numpy as np\n","import pickle\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from sklearn import metrics\n","from sklearn.model_selection import StratifiedKFold\n","import matplotlib.pyplot as plt\n","import keras\n","from sklearn.metrics import ConfusionMatrixDisplay"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2futtCo08HIC"},"outputs":[],"source":["import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","def Augmentation_oct (x_train, labels_train):\n","\n","    # augmentation\n","    batch=np.zeros_like(x_train, dtype=np.float32)\n","    batch_label=np.zeros_like(labels_train, dtype=np.float32)\n","\n","    datagen = ImageDataGenerator(\n","        rotation_range= 5, # rotation\n","        zoom_range= 0.1,\n","        width_shift_range= [-5, 5], # horizontal shift\n","        # vertical_flip= True , # vertical fli\n","        fill_mode='nearest',\n","        data_format='channels_last',\n","        # cval=0,\n","          )\n","\n","\n","    for i in range(len(x_train)):\n","        x1=x_train[i,:,:,:].copy()\n","        x1=x1.reshape((1, ) + x1.shape)\n","        x = datagen.flow(x1, batch_size=1, seed=2020) # to make the result reproducible\n","\n","\n","        batch[i,:,:,:] = x.next()\n","        batch_label[i] = labels_train[i]\n","\n","    ###################################################################\n","    # Final data\n","    ###################################################################\n","\n","    x = np.concatenate([x_train,batch])\n","\n","    labels = np.concatenate([labels_train,batch_label])\n","\n","    ############################\n","\n","    ############################\n","    return x, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aqhPh34AfcOe"},"outputs":[],"source":["import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","def Augmentation_slo (x_train, labels_train):\n","\n","    # augmentation\n","    batch=np.zeros_like(x_train, dtype=np.float32)\n","    batch_label=np.zeros_like(labels_train, dtype=np.float32)\n","\n","    datagen = ImageDataGenerator(\n","        rotation_range= 5, # rotation\n","        width_shift_range= [-30, 30], # horizontal shift\n","        height_shift_range= [-5, 5] , # vertical shift\n","        zoom_range= 0.2,\n","        vertical_flip= True , # vertical flip\n","        brightness_range= [0.2, 1.5],\n","          )\n","\n","    for i in range(len(x_train)):\n","        x1=x_train[i,:,:,:].copy()\n","        x1=x1.reshape((1, ) + x1.shape)\n","        x = datagen.flow(x1, batch_size=1, seed=2020) # to make the result reproducible\n","\n","\n","        batch[i,:,:,:] = x.next()\n","        batch_label[i] = labels_train[i]\n","\n","    ###################################################################\n","    # Final data\n","    ###################################################################\n","\n","    x = np.concatenate([x_train,batch])\n","\n","    labels = np.concatenate([labels_train,batch_label])\n","\n","    ############################\n","\n","    ############################\n","    return x, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkgmjZZ8foyX"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_curve, auc\n","import numpy as np\n","from sklearn import metrics\n","import sklearn\n","\n","# TP = confusion[1,1] # true positive\n","# TN = confusion[0,0] # true negatives\n","# FP = confusion[0,1] # false positives\n","# FN = confusion[1,0] # false negatives\n","\n","def metrics_calculation(y_valid, y_pred, y_prob):\n","\n","    #####################################################\n","    #Get the confusion matrix\n","    #####################################################\n","    ROC_AUC = roc_auc_score(y_valid, y_prob)\n","    f1 = metrics.f1_score(y_valid, y_pred, average='weighted')\n","    precision, recall, thresholds = precision_recall_curve(y_valid, y_prob)\n","    P_R_AUC = auc(recall, precision)\n","    cm = sklearn.metrics.confusion_matrix(y_valid, y_pred, normalize='pred')\n","    #Now the normalize the diagonal entries\n","    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    class_acc = cm.diagonal()\n","\n","    Specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n","    Sensitivity = cm[1,1]/(cm[1,0]+cm[1,1])\n","    Precision   = cm[1,1]/(cm[0,1]+cm[1,1])\n","\n","\n","    return Specificity, Sensitivity, Precision, f1, ROC_AUC, P_R_AUC, class_acc, cm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNzoww19fvXa"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import precision_recall_curve, auc\n","\n","def curve_ploting(ax, axx, mean_fpr, aucs, tprs, y_test, y_pred, classifier, kernel=[]):\n","\n","    ###################### Continuing Ploting ROC curve for each fold and the mean ############\n","\n","    ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n","\n","    mean_tpr = np.mean(tprs, axis=0)\n","    mean_tpr[-1] = 1.0\n","    mean_auc = auc(mean_fpr, mean_tpr)\n","    std_auc = np.std(aucs)\n","    ax.plot(\n","        mean_fpr,\n","        mean_tpr,\n","        color=\"b\",\n","        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n","        lw=2,\n","        alpha=0.8,\n","    )\n","\n","    std_tpr = np.std(tprs, axis=0)\n","    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n","    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n","    ax.fill_between(\n","        mean_fpr,\n","        tprs_lower,\n","        tprs_upper,\n","        color=\"grey\",\n","        alpha=0.2,\n","        label=r\"$\\pm$ 1 std. dev.\",\n","    )\n","\n","    ax.set(\n","        xlim=[-0.05, 1.05],\n","        ylim=[-0.05, 1.05],\n","    )\n","\n","    if kernel:\n","        ax.set_title(f\"ROC Curve of {classifier} classifier ({kernel} kernel) \")\n","    else:\n","        ax.set_title(f\"ROC Curve of {classifier} classifier\")\n","    ax.legend(loc=\"lower right\")\n","\n","    ###################### Continuing Ploting P_R_curve for each fold and the mean ############\n","    ###\n","\n","    no_skill = len(np.array(y_test)[np.array(y_test)==1]) / len(np.array(y_test))\n","\n","    axx.plot([0, 1], [no_skill, no_skill], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n","\n","    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n","\n","    axx.plot(\n","        recall,\n","        precision,\n","        color=\"b\",\n","        label=r\"Mean P_R curve (AUC =  %0.2f)\" % (auc(recall, precision)),\n","        lw=2,\n","        alpha=0.8,\n","    )\n","\n","\n","    # axis labels\n","    axx.set_xlabel('Recall')\n","    axx.set_ylabel('Precision')\n","    # show the legend\n","    axx.legend(loc=\"lower left\")\n","    if kernel:\n","        axx.set_title(f'Precision-Recall Curve of {classifier} classifier ({kernel} kernel)')\n","    else:\n","        axx.set_title(f'Precision-Recall Curve of {classifier} classifier')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bb-zc6m7f2fb"},"outputs":[],"source":["from sklearn.metrics import precision_recall_curve, auc, roc_curve, roc_auc_score\n","import numpy as np\n","\n","def fold_curves(ax, axx, y_valid, fold_number, mean_fpr, pred_proba, tprs=[], aucs=[]):\n","    ############ ROC Curve\n","    lr_fpr, lr_tpr, _ = roc_curve(y_valid, pred_proba)\n","    roc_auc = roc_auc_score(y_valid, pred_proba)\n","    ax.plot(lr_fpr, lr_tpr, lw=1, alpha=0.3, label=r\"P_R_curve fold %d (AUC =  %0.2f)\" % (fold_number, roc_auc))\n","    # axis labels\n","    ax.set_xlabel('False Positive Rate (Positive label: 1.0)')\n","    ax.set_ylabel('True Positive Rate (Positive label: 1.0)')\n","\n","    interp_tpr = np.interp(mean_fpr, lr_fpr, lr_tpr)\n","    interp_tpr[0] = 0.0\n","    tprs.append(interp_tpr)\n","    aucs.append(roc_auc)\n","\n","\n","    ############ P_R Curve\n","    precision, recall, _ = precision_recall_curve(y_valid, pred_proba)\n","    # plot the model precision-recall curve\n","    axx.plot(recall, precision, lw=1, alpha=0.3, label=r\"P_R_curve fold %d (AUC =  %0.2f)\" % (fold_number, auc(recall, precision)))\n","\n","    return tprs, aucs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Utb-JBWKBQ-s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709371401819,"user_tz":-210,"elapsed":17405,"user":{"displayName":"Roya Arian","userId":"08274276132635323793"}},"outputId":"29709170-45e2-4e8b-a31d-29f69e978b70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n","171446536/171446536 [==============================] - 1s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}],"source":["### SLO model\n","from tensorflow.keras.models import Model\n","slo_model =  tf.keras.applications.ResNet101(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(128,128,3),\n","    )\n","\n","for layer in slo_model.layers:\n","    layer._name = 'SLO_' + layer.name\n","\n","new_model = Model(inputs=slo_model.input, outputs=slo_model.output)\n","\n","new_model.save('slo_model_resnet101.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMeiv784pNnu"},"outputs":[],"source":["# merged CNN model for SLO and OCT images\n","\n","# Create two CNN models with the same fully connected layers\n","from tensorflow.keras.models import load_model\n","\n","\n","def merged_model(input_img_slo ,input_img_oct):\n","\n","    ### SLO model\n","    slo_model = load_model('slo_model_resnet101.h5')\n","\n","    for layer in slo_model.layers:\n","        layer.trainable = False\n","\n","\n","    ### OCT model\n","\n","    oct_model =  tf.keras.applications.resnet.ResNet101(\n","        weights='imagenet',\n","        include_top=False,\n","        input_shape=input_img_oct,\n","        )\n","\n","    oct_model.get_layer(index = 0)._name = 'OCT'\n","\n","    for layer in oct_model.layers:\n","        layer.trainable = False\n","\n","\n","    inputs_slo = tf.keras.layers.Input(input_img_slo)\n","    slo_output = tf.keras.layers.Flatten()(slo_model(inputs_slo))\n","\n","\n","    inputs_oct = tf.keras.layers.Input(input_img_oct)\n","    oct_output = tf.keras.layers.Flatten()(oct_model(inputs_oct))\n","\n","\n","    model = tf.keras.layers.Concatenate(axis=-1)([slo_output, oct_output])\n","\n","    model = tf.keras.layers.Dropout(rate = 0.1)(model)\n","\n","    model = tf.keras.layers.Dense(26, activation='relu')(model)\n","\n","    model = tf.keras.layers.Dropout(rate = 0.1)(model)\n","\n","    model = tf.keras.layers.Dense(13, activation='relu')(model)\n","\n","    model = tf.keras.layers.Dropout(rate = 0.1)(model)\n","\n","    model = tf.keras.layers.Dense(415, activation='relu')(model)\n","\n","    model = tf.keras.layers.Dropout(rate = 0.0)(model)\n","\n","    model = tf.keras.layers.Dense(2997, activation='relu')(model)\n","\n","    model = tf.keras.layers.Dropout(rate = 0.3)(model)\n","\n","    outputs = tf.keras.layers.Dense(1, 'sigmoid')(model)\n","\n","\n","\n","    model_merged = tf.keras.Model([inputs_slo, inputs_oct] , outputs)\n","\n","    return model_merged\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8cj2xfPfhyn"},"outputs":[],"source":["import numpy as np\n","\n","def preparing(x, y):\n","\n","    data_slo  = []\n","    data_oct  = []\n","    label     = []\n","    for i in x:\n","      for j in range(len(x[i])):\n","          data_slo.append(np.array(x[i][j][0])/255)\n","          data_oct.append(np.array(x[i][j][1])*255)\n","          label.append(y[i])\n","    data_slo = np.reshape(data_slo, np.shape(data_slo))\n","    data_oct = np.reshape(data_oct, np.shape(data_oct))\n","    return data_slo, data_oct, np.array(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58dYkyaFgBM_"},"outputs":[],"source":["images_train = pickle.load(open(\"train_merged_data_with_sp.pkl\", 'rb'))\n","labels_train = pickle.load(open(\"train_merged_data_with_sp_labels.pkl\", 'rb'))\n","\n","images_test = pickle.load(open(\"test_merged_data_with_sp.pkl\", 'rb'))\n","labels_test = pickle.load(open(\"test_merged_data_with_sp_labels.pkl\", 'rb'))\n","\n","images_test_slo, images_test_oct, labels_test_slo = preparing(images_test,labels_test)\n","\n","images_test_slo = np.repeat (images_test_slo, repeats = 3, axis = 3)\n","images_test_oct = np.repeat (images_test_oct, repeats = 3, axis = 3)\n","#####################################################################\n","## Parameters\n","#####################################################################\n","channel = 1\n","number_class = 2\n","\n","cnn_acc    = []\n","cnn_se     = []\n","cnn_sp     = []\n","cnn_pr     = []\n","cnn_f1     = []\n","cnn_auc    = []\n","cnn_pr_auc = []\n","\n","test_acc    = []\n","test_se     = []\n","test_sp     = []\n","test_pr     = []\n","test_f1     = []\n","test_auc    = []\n","test_pr_auc = []\n","\n","\n","class_acc = np.zeros((number_class))\n","class_acc_test = np.zeros((number_class))\n","\n","target_names = ['Normal' , 'MS']\n","confusion_matrix = np.zeros((number_class, number_class))\n","confusion_matrix_test = np.zeros((number_class, number_class))\n","\n","y_test = []\n","tprs   = []\n","aucs   = []\n","y_pred = []\n","x_test = {}\n","\n","mean_fpr  = np.linspace(0, 1, 100)\n","fig, ax   = plt.subplots(figsize=(5, 5))\n","fig1, ax1 = plt.subplots(figsize=(5, 5))\n","\n","\n","#### model parameters\n","batch_size        = 16\n","epoch             = 100\n","learning_rate     = 0.000275167073\n","#####################################################################\n","## Applying kfold\n","#####################################################################\n","\n","nfold = 5  #please enter number of folds\n","\n","kf_nfold = StratifiedKFold(n_splits=nfold, random_state=42, shuffle=True)\n","\n","n = 0\n","for train_index, val_index in kf_nfold.split(images_train,list(labels_train.values())):\n","    n = n+1\n","    # print(train_index, val_index)  # you can watch train and validation index using this comment\n","    print(f'---------------------------------------------------------------------\\\n","          \\n \\t\\t\\t {n}th fold \\n---------------------------------------------------------------------'\\\n","          ,end = '\\n\\n\\n' )\n","    x_train = {i: images_train[list(images_train.keys())[i]] for i in train_index}\n","    x_valid = {i: images_train[list(images_train.keys())[i]] for i in val_index}\n","\n","    y_trainn = {i: labels_train[list(labels_train.keys())[i]] for i in train_index}\n","    y_validd = {i: labels_train[list(labels_train.keys())[i]] for i in val_index}\n","\n","\n","    ################## preparing\n","\n","    x_train_slo, x_train_oct, y_train = preparing(x_train,y_trainn)\n","    x_valid_slo, x_valid_oct, y_valid = preparing(x_valid,y_validd)\n","\n","    x_test[n] = x_valid_slo\n","    ################# Augmentation\n","    x_train_slo, y_train_slo = Augmentation_slo(x_train_slo,y_train)\n","\n","    x_train_oct, y_train_oct = Augmentation_oct(x_train_oct,y_train)\n","\n","\n","    indices = np.random.permutation (len (x_train_slo))\n","    x_train_slo = x_train_slo [indices]\n","    y_train_slo = y_train_slo [indices]\n","\n","    x_train_oct = x_train_oct [indices]\n","    y_train_oct = y_train_oct [indices]\n","\n","\n","    x_train_slo = np.repeat (x_train_slo, repeats = 3, axis = 3)\n","\n","    x_train_oct = np.repeat (x_train_oct, repeats = 3, axis = 3)\n","\n","    x_valid_slo = np.repeat (x_valid_slo, repeats = 3, axis = 3)\n","\n","    x_valid_oct = np.repeat (x_valid_oct, repeats = 3, axis = 3)\n","\n","    ####################################################################\n","    # classification\n","    ####################################################################\n","\n","    input_img_slo = (np.shape(x_train_slo)[1], np.shape(x_train_slo)[2], 3)\n","    input_img_oct = (np.shape(x_train_oct)[1], np.shape(x_train_oct)[2], 3)\n","\n","    model = merged_model(input_img_slo=input_img_slo, input_img_oct=input_img_oct)\n","\n","    METRICS = [\n","#      keras.metrics.TruePositives(name='tp'),\n","#      keras.metrics.FalsePositives(name='fp'),\n","#      keras.metrics.TrueNegatives(name='tn'),\n","#      keras.metrics.FalseNegatives(name='fn'),\n","      keras.metrics.BinaryAccuracy(name='accuracy'),\n","#      keras.metrics.Precision(name='precision'),\n","#      keras.metrics.Recall(name='recall'),\n","      keras.metrics.AUC(name='auc'),\n","#      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n","      ]\n","\n","\n","    my_optimizer =  tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    model.compile(optimizer=my_optimizer, loss=\"binary_crossentropy\", metrics=METRICS)\n","    callbacks = [EarlyStopping(patience=20, verbose=1),\n","        ReduceLROnPlateau(factor=0.1, patience=10, min_lr=1e-6),\n","        ModelCheckpoint(f'slo_oct{n}.h5', verbose=1, save_best_only=True, save_weights_only=True)]\n","\n","    #################################\n","    ###### Applying model  ###########\n","    #################################\n","\n","\n","    results = model.fit([x_train_slo, x_train_oct], y_train_slo, batch_size=batch_size, epochs=epoch, callbacks=callbacks,\\\n","                    validation_data=([x_valid_slo, x_valid_oct], np.asarray(y_valid, dtype=np.float64)))\n","\n","\n","    plt.figure(figsize=(5, 5))\n","    plt.title(f\"Learning curve {n}th fold\")\n","    plt.plot(results.history[\"loss\"][:-7], label=\"loss\")\n","    plt.plot(results.history[\"val_loss\"][:-7], label=\"val_loss\")\n","    plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"log_loss\")\n","    plt.legend()\n","\n","    plt.figure(figsize=(5, 5))\n","    plt.title(f\"Learning curve {n}th fold\")\n","    plt.plot(results.history[\"accuracy\"], label=\"accuracy\")\n","    plt.plot(results.history[\"val_accuracy\"], label=\"val_accuracy\")\n","    plt.plot( np.argmax(results.history[\"val_accuracy\"]), np.max(results.history[\"val_accuracy\"]),\\\n","             marker=\"x\", color=\"r\", label=\"best accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"accuracy\")\n","    plt.legend()\n","\n","\n","    # load the best model\n","    model.load_weights(f'slo_oct{n}.h5')\n","\n","\n","    pred_proba = model.predict([x_valid_slo, x_valid_oct]).ravel()\n","    pred_class = (pred_proba > 0.5).astype(np.uint8)\n","\n","\n","    ##### calculating metrics\n","\n","    cnn_acc.append(metrics.accuracy_score(y_valid, pred_class))\n","    print(f'accuracy of {n}th fold : {metrics.accuracy_score(y_valid, pred_class)}')\n","    SP, SE, PR, f1, ROC_AUC, P_R_AUC, Class_acc, cm = metrics_calculation(y_valid, pred_class, pred_proba)\n","\n","    cnn_sp.append(SP)\n","    cnn_se.append(SE)\n","    cnn_pr.append(PR)\n","    cnn_f1.append(f1)\n","    cnn_auc.append(ROC_AUC)\n","    cnn_pr_auc.append(P_R_AUC)\n","\n","    #################### acc for each class ##################\n","    class_acc = np.add(class_acc,Class_acc)\n","\n","    ###################### Total confusion_matrix for poly kernel ############\n","    confusion_matrix = np.add(confusion_matrix,cm)\n","\n","######################## internal test\n","    pred_proba_test = model.predict([images_test_slo, images_test_oct]).ravel()\n","    pred_class_test = (pred_proba_test > 0.5).astype(np.uint8)\n","\n","\n","    ##### calculating metrics\n","\n","    print(f'test accuracy of {n}th fold : {metrics.accuracy_score(labels_test_slo, pred_class_test)}')\n","    SP, SE, PR, f1, ROC_AUC, P_R_AUC, Class_acc, cm = metrics_calculation(labels_test_slo, pred_class_test, pred_proba_test)\n","    test_acc.append(metrics.accuracy_score(labels_test_slo, pred_class_test))\n","    test_sp.append(SP)\n","    test_se.append(SE)\n","    test_pr.append(PR)\n","    test_f1.append(f1)\n","    test_auc.append(ROC_AUC)\n","    test_pr_auc.append(P_R_AUC)\n","\n","    #################### acc for each class ##################\n","    class_acc_test  = np.add(class_acc_test,Class_acc)\n","\n","    ###################### Total confusion_matrix for poly kernel ############\n","    confusion_matrix_test = np.add(confusion_matrix_test,cm)\n","\n","\n","########################################\n","#     Metrics printing\n","########################################\n","cnn_accc     = np.mean(cnn_acc)\n","cnn_spp      = np.mean(cnn_sp)\n","cnn_see      = np.mean(cnn_se)\n","cnn_prr      = np.mean(cnn_pr)\n","cnn_f11      = np.mean(cnn_f1)\n","cnn_aucc     = np.mean(cnn_auc)\n","cnn_pr_aucc  = np.mean(cnn_pr_auc)\n","\n","###################### internal test\n","test_accc     = np.mean(test_acc)\n","test_spp      = np.mean(test_sp)\n","test_see      = np.mean(test_se)\n","test_prr      = np.mean(test_pr)\n","test_f11      = np.mean(test_f1)\n","test_aucc     = np.mean(test_auc)\n","test_pr_aucc  = np.mean(test_pr_auc)\n","\n","#################### acc for each class ##################\n","class_acc  = class_acc/nfold\n","class_acc_test  = class_acc_test/nfold\n","\n","print('cnn_acc     = %f' % cnn_accc)\n","print('cnn_sp      = %f' % cnn_spp)\n","print('cnn_se      = %f' % cnn_see)\n","print('cnn_pr      = %f' % cnn_prr)\n","print('cnn_f1      = %f' % cnn_f11)\n","print('cnn_auc     = %f' % cnn_aucc)\n","print('cnn_pr_auc  = %f' % cnn_pr_aucc, end='\\n\\n')\n","\n","\n","print('acc of class %s' % target_names[0], '= %f' % class_acc[0])\n","print('acc of class %s' % target_names[1], '= %f' % class_acc[1], end='\\n\\n')\n","\n","print('test_acc     = %f' % test_accc)\n","print('test_sp      = %f' % test_spp)\n","print('test_se      = %f' % test_see)\n","print('test_pr      = %f' % test_prr)\n","print('test_f1      = %f' % test_f11)\n","print('test_auc     = %f' % test_aucc)\n","print('test_pr_auc  = %f' % test_pr_aucc, end='\\n\\n')\n","\n","\n","print('test acc of class %s' % target_names[0], '= %f' % class_acc_test[0])\n","print('test acc of class %s' % target_names[1], '= %f' % class_acc_test[1], end='\\n\\n')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1X5KSWs2IQ_lfJDbtJyQb-tizrwOzi214","timestamp":1708669074796},{"file_id":"1mW2xs9vequREQu5cw-KwxryvnI-xyAvz","timestamp":1702184356342},{"file_id":"14UYD-86zCDg88Hs6TGsFBUnxOCf47ZH_","timestamp":1689395600141},{"file_id":"1pkvlho1ns0k7OcSjO262Sah8deDVmRtr","timestamp":1670219784477},{"file_id":"1o4Zti0F0345opF_pzxyuK3U8RiNFZvBx","timestamp":1664082347587},{"file_id":"1WHvCJc8V_E_RH2lkeoZRWAlk6gE2hRN5","timestamp":1663578806373},{"file_id":"12MbcL6T0m6tjRLQXjId8eZyDtPO7esEG","timestamp":1663407037239},{"file_id":"1mRREGWQO-koodfm0shaz4g0RCJn1jsM4","timestamp":1603917567583}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}